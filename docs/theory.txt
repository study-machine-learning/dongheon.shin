[이론]

1. 도입

  - 스크레이핑 : 웹 사이트에 있는 정보를 추출하는 과정을 의미하며, HTML 구조를 분석하는 과정을 포함
  - 크롤링 : 정기적으로 돌며 정보를 추출하는 기술
  - 머신러닝에 사용할 수 있는 데이터의 구조 : 필요한 부분만을 크롤링해 저장하는 것이 중요하며, 저장하는 구조도 설계 필요

2. crontab

- 기본

  - 템플릿 : <분> <시> <일> <월> <요일> <명령어>
  - 특징 : 환경 변수를 전개할 수 없음

- 템플릿

  - 확장

    - 리스트 : 1,2,3,...
    - 범위 : -
    - 와일드카드 : *
    - 간격 : */range

  - 구성 요소

    - 분 : 0-59
    - 시 : 0-23
    - 일 : 1-31
    - 월 : 1-12
    - 요일 : 0-7 (일요일은 0, 7 사용)

3. YAML (Yet Another Markup Language -> YAML Ain't Markup Language)

- 형식

  - 들여쓰기로 깊이를 조절하는 구조
  - 주석 : #로 시작
  - 해시 : <키>: <값>
  - 배열

    - 기본 : -로 나열
    - 중첩 : -를 상위에 선언하고 들여쓰기한 요소에 배열을 추가하는 방식

- 다른 텍스트 데이터 포맷과 구분되는 특징

  - 플로우 스타일 제공 : 한 줄에 이어 작성하는 스타일 - 배열은 [], 해시는 {}로 표현
  - 여러 줄에 문자열 표현 : |
  - 참조

    - 앵커 (&) : 심볼릭 선언
    - 별칭 (*) : 참조

4. CSV

- 콤마로 값을 분리, 줄바꿈 문자로 행을 분리
- "로 감싸 표현하며 생략 가능하나 데이터 내부에 줄바꿈이나 "가 있다면 생략 불가

5. 머신러닝

- 개요

  - 규모가 있는 샘플 데이터로 넣어 분석 시킨 후, 일정한 규칙을 찾아 다른 데이터를 분류하거나 미래를 예측
  - 특징 추출 : 데이터가 어떤 특징을 갖는지 파악하고 벡터화 하는 작업이 필요함
  - 응용 분야 : 클래스 분류, 클러스터링, 추천, 회귀, 차언 축소

- 종류

  - 지도 학습 : 데이터와 답을 함께 입력하고 다른 데이터의 답을 예측
  - 비지도 학습 : 데이터는 입력하지만 답은 입력하지 않고 규칙성을 찾는데 사용
  - 강화 학습 : 부분적으로 답을 입력하고 데이터를 기반으로 최적의 답을 찾아냄

- 흐름

  - 전처리 : 데이터 수집 -> 데이터 가공
  - 데이터 학습 : 학습 방법 선택 -> 매개변수 조정 -> 모델 학습
  - 모델 평가

- 초과 학습

  - 훈련 목적으로 제공되는 샘플 데이터에 대해서는 학습되어 있으나, 새로운 데이터에 대해 제대로 예측하지 못하는 현상
  - 데이터가 너무 적거나 모델에 비해서 문제가 너무 복잡할 경우 발생

- 회귀 분석

  - 개요

    - 회귀 : 종속 변수를 여러 독립 변수로부터 추정하는 과정
    - 분류

      - 선형 회귀 : 1차원 함수 형태
      - 다중 회귀 : 2차원 이상의 함수로 표현

6. SVM

- 개요

  - 여러 종류의 데이터를 구분하기 위한 식별 평면을 만들어 패턴을 인식하는 방법
  - 구분선에는 여러 후보군이 있으나, 모든 데이터와 식별 평면 사이의 직선 거리의 합이 최소가 되는 평면을 선택

7. 랜덤 포레스트

- 개요

  - 여러 의사 결정 트리를 생성하고 각 트리로부터 얻은 결과를 종합하여 판단하는 기법 : 앙상블
  - 일반적으로는 부정확한 학습 방법이나 집단 학습을 통해 정밀도를 높일 수 있음

9. 교차 검증

- 개요

  - 특정 데이터를 학습 데이터와 테스트 데이터로 분할하여 학습하고 타당성을 검증하는 과정
  - sk_learn.model_selection.train_test_split 메서드로 적용한 방법도 교차 검증에 해당함

- K 분할 교차 검증

  - 데이터를 K개로 분할
  - 하나를 테스트 데이터, 나머지를 학습 데이터로 활용하여 모델 생성 후 검증
  - K번 반복하여 얻은 정밀도의 평균값을 최종 정밀도로 판단

10. 그리드 서치

- 개요

  - SVM와 같은 학습기의 성능은 매개변수를 얼마나 잘 튜닝했는가와 연관이 있음
  - 성능이 좋은 매개변수를 자동으로 조사하여 가장 성능이 좋은 값을 사용하는 방법

11. 딥 러닝

- 개요

  - 1980년대부터 있던 개념이나 컴퓨팅 파워나 리소스, 비즈니스적 환경으로 빛을 보기 시작하면서 괄목할 성능을 이끌어내며넛 대두됨
  - 특징량 추출을 기계가 자동으로 추출한다는 것이 차이점이며, 신경망을 기반으로 하는 학습 구조가 특징

- 신경망 - 뉴럴 네트워크

  - 개요

    - 컴퓨터에게 학습 능력을 부여하기 위해 인간의 신경망을 본 따 만든 것으로, 여러 뉴런이 연결되어 있는 구조를 가지고 있음
    - 신경망은 입력층, 중간층 (은폐층), 출력층으로 구성되어 있으며, 데이터가 입력층부터 순차적으로 거쳐서 결과를 도출해 내는 것
    - 신경망 학습은 각 뉴런이 가지고 있는 파라미터를 조절하는 과정으로 봐도 무방함
    - 신경망을 3개 이상 중첩시키면 DNN으로 분류함

  - 퍼셉트론

    - N개의 입력 신호와 하나의 출력을 갖는 신경망을 구성하는 기본 단위
    - 입력 신호에 대한 선형대수 조합과 임계치를 판단하는 활성 함수로 구성됨

12. Softmax

- 개요

  - n개의 입력에 대해 0~1 사이에 있으며 합이 1이 되는 값으로 변환해주는 함수
  - 입력의 총합이 1이므로 확률값으로 변환하는 함수로 볼 수 있음
  - 뉴런의 출력값을 정규화 할 목적으로 사용되며, 멀티 클래스 분류에 많이 사용됨

- 수식

  - 정의 : softmax(x) = e ** x / sum([e ** x for i in range(size)])
  - 텐서플로우 API : tf.nn.softmax(values)

13. 크로스 엔트로피

- 개요

  - 오차를 계산하는 방법 중 하나로, 결과가 낮을수록 더 좋은 예측을 하는 모델이라 이해할 수 있음 (cf. MSE)
  - 결과 값에 자연 로그를 취한 값과 예상 레이블을 곱한 값의 총합으로 산출
  - MSE와 비교했을 때 학습 결과는 유사할 수 있으나, 학습 속도는 조금 더 빠르다는 장점이 있음

- 수식

  - 정의 : cross_entropy(y) = -sum([y` * log(y) for i in range(size)])
  - 텐서플로우 API : -tf.reduce_sum(y_ * tf.log(y))

14. CNN

- 개요

  - 입력층과 출력층 사이의 중간층을 컨볼루션 계층과 폴링 계층으로 구성한 신경망으로, 이미지나 영상 인식에 탁월한 성능을 보임
  - 사람이 수작업으로 특징 표현을 입력하는 것이 아니라 컴퓨터가 스스로 특징 표현을 만들어 내는 것이 큰 차이점

- 구성

  - 컨볼루션 계층

    - 연결 가중치와 가중합 등 일반적인 신경망의 개념을 활용하지 않고 컨볼루션 커널 혹은 필터를 사용하여 원본 데이터로부터 특징 맵을 추출하는 계층
    - 원본 데이터에 마스크 행렬을 투영한 결과에 활성화 함수를 적용하여 최종 결과를 도출

  - 폴링 계층

    - 컨볼류션 계층으로부터 얻은 특징 맵을 축소하는 계층
    - 각 특징의 최대값을 사용하는 최대 풀링과 평균값을 사용하는 평균 폴링으로 구분됨

  - 전결합층

    - 각 층의 유닛을 결합하여 2차원의 특징 맵을 1차원으로 전개하는 역할을 담당하는 계층
    - 활성화 함수 등을 사용하여 특징을 강조하거나 드롭아웃으로 과적합을 막을 수 있음
